#!/usr/bin/env python3
# -*- coding: utf-8 -*-

#
# Copyright Red Hat Inc
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# This file is part of Cockpit.
#


"""This script requires standard-test-roles:
https://pagure.io/standard-test-roles/

"""

import os
import sys
import json
import jinja2
import shutil
import argparse
import datetime
import tempfile
import itertools
import subprocess
import urllib.parse
import urllib.request

UPSTREAM_PAGURE = "https://upstreamfirst.fedorainfracloud.org/api/0/"
UPSTREAM_BASE = "https://upstreamfirst.fedorainfracloud.org/"
DISTGIT_BASE = "https://src.fedoraproject.org/git/rpms/"


THIS_DIR = os.path.dirname(os.path.abspath(__file__))
IN_J2_WIKI_TEMPLATE = 'stat.j2'

def retrieve(url):
    return urllib.request.urlopen(url).read().decode('utf-8')

def projects():
    url = urllib.parse.urljoin(UPSTREAM_PAGURE, "projects")
    for project in json.loads(retrieve(url))["projects"]:
        if not project.get("parent"):
            yield project["name"]

def repos():
    base = os.path.dirname(__file__)
    with open(os.path.join(base, "repos"), "rb") as f:
        while True:
            line = f.readline()
            if not line:
                break
            line = line.strip()
            if line:
                yield line.decode("utf-8")

def clone(url, directory):
    target = os.path.join(directory, os.path.basename(url))
    while os.path.exists(target):
        target += ".x"
    try:
        # Do shallow clone with a history truncated.
        subprocess.check_call(["git", "clone", "--depth=1", url, target],
                              cwd=directory, stdout=sys.stderr.fileno())
    except subprocess.CalledProcessError:
        return None
    return target

def count(stats, field, project):
    """Adds a project to a list for specific category:
    stats - is a dictionary in next format:
    {'atomic': ["pkg1", "pkg2", "pkg3"],
     'legacy': ["pkg2",],
     'tests.yaml': ["pkg1",]}

    """
    if field not in stats:
        stats[field] = []
    if project not in stats[field]:
        stats[field].append(project)

def tags(repo, standard):
    try:
        playbook = standard and "tests.yml" or "test_local.yml"
        environ = os.environ.copy()
        environ["LC_ALL"] = "C"
        output = subprocess.check_output([ "ansible-playbook",
                                          "--list-tags", playbook ],
                                         env=environ, cwd=repo)
    except subprocess.CalledProcessError:
        output = b""
    for line in output.decode("utf-8").split("\n"):
        if "TASK TAGS" in line:
            name, unused, tags = line.partition(":")
            for tag in tags.strip(" []").split(","):
                yield tag.strip()

def gather(repo, project, stats, location):
    """Looks for standard tests locations. If found adds it to the list.

    """
    # Standard entry point
    path = os.path.join(repo, "tests.yml")
    standard = os.path.exists(path)
    if standard:
        count(stats, location + "-tests.yml", project)
    if "atomic" in tags(repo, standard):
        count(stats, location + "-atomic", project)
    if "classic" in tags(repo, standard):
        count(stats, location + "-classic", project)
    if "container" in tags(repo, standard):
        count(stats, location + "-container", project)

def main():
    parser = argparse.ArgumentParser(
        description='Gather stats about tests in dist-git')
    parser.add_argument("--wikiout", metavar='FILE', default=None,
                        help="Dump output to FILE in MediaWiki format.")
    parser.add_argument("--keepworkdir", help="Keep workdir with cloned repos.",
                        action='store_true')
    parser.add_argument("--short", help="Proceed only first 10 repos.",
                        action='store_true')
    opts = parser.parse_args()
    stop = None
    if opts.short:
        stop = 10
    stats = { }
    directory = tempfile.mkdtemp(prefix="test-stats")
    # Gather statistics for dist-git.
    known_repos = itertools.chain(repos(), projects())
    for project in itertools.islice(known_repos, stop):
        url = urllib.parse.urljoin(DISTGIT_BASE, project)
        repo = clone(url, directory)
        if repo:
            count(stats, "distgit", project)
            sub = os.path.join(repo, "tests")
            if os.path.exists(sub):
                gather(sub, project, stats, "distgit")
        else:
            count(stats, "missing", project)
    # Gather statistics for upstream first projects.
    for project in itertools.islice(projects(), stop):
        url = urllib.parse.urljoin(UPSTREAM_BASE, project)
        repo = clone(url, directory)
        if repo:
            count(stats, "upstreamfirst", project)
            gather(repo, project, stats, "upstreamfirst")
    if not opts.keepworkdir:
        shutil.rmtree(directory)
    # Dump results to stdout.
    for name in list(stats.keys()):
        stats["{0}-length".format(name)] = len(stats[name])
    json.dump(stats, sys.stdout, indent=4)
    # Dump results in MediaWiki format.
    if opts.wikiout:
        pkgs_categories = [category
                           for category, pkgs in stats.items()
                           if isinstance(pkgs, list)]
        # Holds all known packages.
        know_pkgs = set()
        for category in pkgs_categories:
                know_pkgs.update(stats[category])
        know_pkgs = sorted(list(know_pkgs), key=lambda s: s.lower())
        j2_pkgs = []
        for pkg in know_pkgs:
            p = {}
            p['name'] = pkg
            p['dg_testsyml'] = pkg in stats.get("distgit-tests.yml", [])
            p['dg_classic'] = pkg in stats.get("distgit-classic", [])
            p['dg_container'] = pkg in stats.get("distgit-container", [])
            p['dg_atomic'] = pkg in stats.get("distgit-atomic", [])
            p['up_testsyml'] = pkg in stats.get("upstreamfirst-tests.yml", [])
            p['up_classic'] = pkg in stats.get("upstreamfirst-classic", [])
            p['up_container'] = pkg in stats.get("upstreamfirst-container", [])
            p['up_atomic'] = pkg in stats.get("upstreamfirst-atomic", [])
            p['dg_missing'] = pkg in stats.get("missing", [])
            j2_pkgs.append(p)
        j2_total = {}
        j2_total['dg_testsyml'] = len(stats.get("distgit-tests.yml", []))
        j2_total['dg_classic'] = len(stats.get("distgit-classic", []))
        j2_total['dg_container'] = len(stats.get("distgit-container", []))
        j2_total['dg_atomic'] = len(stats.get("distgit-atomic", []))
        j2_total['up_testsyml'] = len(stats.get("upstreamfirst-tests.yml", []))
        j2_total['up_classic'] = len(stats.get("upstreamfirst-classic", []))
        j2_total['up_container'] = len(stats.get("upstreamfirst-container", []))
        j2_total['up_atomic'] = len(stats.get("upstreamfirst-atomic", []))
        j2_total['dg_missing'] = len(stats.get("missing", []))
        j2_total['known'] = len(know_pkgs)
        j2_loader = jinja2.FileSystemLoader(THIS_DIR)
        j2_env = jinja2.Environment(loader=j2_loader, trim_blocks=True)
        template = j2_env.get_template(IN_J2_WIKI_TEMPLATE)
        template_vars = {}
        template_vars['updated'] = datetime.datetime.utcnow()
        template_vars['total'] = j2_total
        template_vars['pkgs'] = j2_pkgs
        with open(opts.wikiout, 'w') as mwfile:
            for line in template.render(template_vars):
                mwfile.write(line)
    return 0

if __name__ == '__main__':
        sys.exit(main())
